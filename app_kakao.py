import streamlit as st
import pandas as pd
import os
import platform
from collections import Counter
from konlpy.tag import Okt
import google.generativeai as genai
import plotly.express as px
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import json
from io import BytesIO

# -----------------------------------------------------------------------------
# 1. í˜ì´ì§€ ì„¤ì • ë° í°íŠ¸ ì„¤ì • (ë°°í¬ í™˜ê²½ ëŒ€ì‘)
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="ì¹´ì¹´ì˜¤í†¡ ëŒ€í™” ë¶„ì„ê¸° (Ultimate)",
    page_icon="ğŸ",
    layout="wide"
)

# í°íŠ¸ ì„¤ì • ìš°íšŒ ë¡œì§
def get_font_path():
    paths = [
        '/usr/share/fonts/truetype/nanum/NanumGothic.ttf', # Linux (Streamlit Cloud)
        '/System/Library/Fonts/AppleGothic.ttf',          # Mac
        'C:/Windows/Fonts/malgun.ttf'                     # Windows
    ]
    for p in paths:
        if os.path.exists(p):
            return p
    return None # í°íŠ¸ê°€ ì—†ì„ ê²½ìš° None ë°˜í™˜ (WordCloud ê¸°ë³¸í°íŠ¸ ì‚¬ìš©)

FONT_PATH = get_font_path()

# Secretsì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    API_KEY = None
    st.sidebar.warning("âš ï¸ Streamlit Secretsì— 'GEMINI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# -----------------------------------------------------------------------------
# 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# -----------------------------------------------------------------------------
@st.cache_resource
def get_tokenizer():
    return Okt()

@st.cache_data
def load_data(uploaded_files):
    all_data = []
    for uploaded_file in uploaded_files:
        try:
            # í—¤ë” íƒìƒ‰ ë° ë¡œë“œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            content = uploaded_file.read()
            for enc in ['utf-8', 'cp949', 'utf-16']:
                try:
                    decoded = content.decode(enc)
                    df_temp = pd.read_csv(BytesIO(content), encoding=enc, header=None)
                    break
                except: continue
            
            header_row_idx = 0
            for idx, row in df_temp.iterrows():
                if 'Date' in str(row.values) and 'User' in str(row.values):
                    header_row_idx = idx
                    break
            
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, header=header_row_idx, encoding=enc)
            df.columns = [str(c).strip() for c in df.columns]
            
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
                df = df.dropna(subset=['Date'])
                df['Year'] = df['Date'].dt.year
                all_data.append(df)
        except Exception as e:
            st.error(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            
    return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()

@st.cache_data
def extract_nouns(text_data, top_n=50):
    okt = get_tokenizer()
    nouns = []
    sample_text = text_data[:10000] if len(text_data) > 10000 else text_data
    for text in sample_text:
        if isinstance(text, str):
            nouns.extend([n for n in okt.nouns(text) if len(n) > 1])
    return Counter(nouns).most_common(top_n)

# -----------------------------------------------------------------------------
# 3. UI ì»´í¬ë„ŒíŠ¸ (PNG ë‹¤ìš´ë¡œë“œ ì¶”ê°€)
# -----------------------------------------------------------------------------
def get_time_of_day_label(hour):
    if 5 <= hour < 12: return "ğŸŒ ì•„ì¹¨í˜• ì¸ê°„"
    elif 12 <= hour < 18: return "â˜• ì˜¤í›„ì˜ ìˆ˜ë‹¤ìŸì´"
    elif 18 <= hour < 24: return "ğŸŒ™ ì €ë…í˜• ì¸ê°„"
    else: return "ğŸ¦‰ ì˜¬ë¹¼ë¯¸ì¡±"

def show_wrapped_ui(df, year):
    # CSS ìœ ì§€ (ìƒëµ, ì›ë³¸ ì½”ë“œì™€ ë™ì¼)
    st.markdown(f"## ğŸ‰ {year}ë…„ ìš°ë¦¬ë“¤ì˜ ê¸°ë¡ (Wrapped)")
    
    total_msgs = len(df)
    daily_counts = df['Date'].dt.date.value_counts()
    best_day_str = daily_counts.idxmax().strftime("%mì›” %dì¼") if not daily_counts.empty else "-"
    
    # ... (ê¸°ì¡´ í†µê³„ ê³„ì‚° ë¡œì§ ë™ì¼) ...
    
    # AI ë¶„ì„ (Secretsì˜ API_KEY ì‚¬ìš©)
    if API_KEY and st.button("âœ¨ AI ì£¼ì œ ë¶„ì„"):
        with st.spinner("ë¶„ì„ ì¤‘..."):
            genai.configure(api_key=API_KEY)
            model = genai.GenerativeModel('gemini-2.0-flash') # ìµœì‹  ëª¨ë¸ëª… í™•ì¸ í•„ìš”
            sample = df['Message'].dropna().sample(min(100, len(df))).tolist()
            response = model.generate_content(f"ë‹¤ìŒ ì¹´í†¡ ì£¼ì œ 5ê°€ì§€ë¥¼ ì½¤ë§ˆë¡œ êµ¬ë¶„: {sample}")
            st.write(response.text)

def show_ai_report_ui(df, year):
    st.subheader(f"ğŸ¤– Gemini ì‹¬ì¸µ ë¦¬í¬íŠ¸")
    if not API_KEY:
        st.warning("API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    if st.button("ğŸ“‘ ë¦¬í¬íŠ¸ ìƒì„±"):
        with st.spinner("ì‘ì„± ì¤‘..."):
            genai.configure(api_key=API_KEY)
            model = genai.GenerativeModel('gemini-2.0-flash')
            sample = df['Message'].dropna().sample(min(150, len(df))).tolist()
            prompt = f"ë‹¤ìŒ ëŒ€í™”ë¥¼ ë¶„ì„í•´ ë¶„ìœ„ê¸°, ì£¼ì œ, ì´í‰ì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì‘ì„±: {sample}"
            response = model.generate_content(prompt)
            st.markdown(response.text)
            st.download_button("ğŸ“¥ ë¦¬í¬íŠ¸(.txt) ë‹¤ìš´ë¡œë“œ", response.text, file_name=f"report_{year}.txt")

# -----------------------------------------------------------------------------
# 4. ë©”ì¸ ë¡œì§
# -----------------------------------------------------------------------------
uploaded_files = st.sidebar.file_uploader("ì¹´ì¹´ì˜¤í†¡ CSV ì—…ë¡œë“œ", type=['csv'], accept_multiple_files=True)

if uploaded_files:
    df = load_data(uploaded_files)
    if not df.empty:
        all_years = sorted(df['Year'].dropna().astype(int).unique())
        selected_year = st.sidebar.selectbox("ì—°ë„ ì„ íƒ", all_years, index=len(all_years)-1)
        year_df = df[df['Year'] == selected_year]
        
        tabs = st.tabs(["ğŸ Wrapped", "ğŸ­ ì„±ê²© ë¶„ì„", "ğŸ¤– ì‹¬ì¸µ ë¦¬í¬íŠ¸", "ğŸ“Š ë°œí™”ëŸ‰", "â˜ï¸ í‚¤ì›Œë“œ"])
        
        with tabs[0]: show_wrapped_ui(year_df, selected_year)
        
        with tabs[2]: show_ai_report_ui(year_df, selected_year)
        
        with tabs[4]: # í‚¤ì›Œë“œ & PNG ë‹¤ìš´ë¡œë“œ
            st.subheader("ì£¼ìš” í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")
            if st.button("ë¶„ì„ ì‹œì‘"):
                nouns = extract_nouns(year_df['Message'].dropna().tolist())
                if nouns:
                    wc = WordCloud(font_path=FONT_PATH, background_color="white", width=800, height=400).generate_from_frequencies(dict(nouns))
                    
                    # ì´ë¯¸ì§€ í‘œì‹œ
                    fig, ax = plt.subplots()
                    ax.imshow(wc, interpolation='bilinear')
                    ax.axis("off")
                    st.pyplot(fig)
                    
                    # PNG ë‹¤ìš´ë¡œë“œ ë¡œì§
                    buf = BytesIO()
                    plt.savefig(buf, format="png")
                    st.download_button(
                        label="ğŸ“¥ ì›Œë“œí´ë¼ìš°ë“œ PNG ë‹¤ìš´ë¡œë“œ",
                        data=buf.getvalue(),
                        file_name=f"wordcloud_{selected_year}.png",
                        mime="image/png"
                    )
                else:
                    st.warning("ì¶”ì¶œëœ ëª…ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

else:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ì¹´ì¹´ì˜¤í†¡ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
